# 第八章补充：后训练模型评估

## 8.5 后训练模型评估

本节对 V3B 后训练模型进行全面评估，包括评估指标定义、评估结果分析、消融实验和训练效率分析。

### 8.5.1 评估指标定义

为全面评估后训练模型在教学场景中的表现，本文采用以下三类核心指标：

**1. Key Point Coverage (关键点覆盖率)**

定义：模型回答是否覆盖所有预期的关键知识点。

计算方式：
$$
\text{Coverage} = \frac{\text{命中的关键点数量}}{\text{总关键点数量}}
$$

评分标准：
- 1.0：所有关键点均被覆盖
- 0.5-0.99：部分关键点被覆盖
- 0.0：未覆盖任何关键点

**2. Response Format (响应格式符合度)**

定义：模型回答是否符合预定义的教学模板结构。

评分标准：
- Style 任务：必须包含 `### 结论`、`### 推导`、`### 检查（单位/边界条件/极限情况）`
- Writing 任务：必须包含 `### 问题诊断`、`### 改进建议`、`### 规范说明`

计算方式：
$$
\text{Format} = \begin{cases}
1.0 & \text{所有必需模板标记均存在} \\
0.0 & \text{缺少任一必需模板标记}
\end{cases}
$$

**3. Refusal Accuracy (拒答准确率)**

定义：模型是否正确识别超出能力范围的问题并拒答。

计算方式：
$$
\text{Refusal} = \frac{\text{正确拒答 + 正确回答}}{\text{总样本数}}
$$

评分标准：
- 应该拒答的问题：模型正确拒答 → 1分
- 应该回答的问题：模型正常回答 → 1分
- 误拒答或误回答 → 0分

### 8.5.2 V3B 模型评估结果

基于 17 个评估样本（11 个 Style + 6 个 Writing），V3B 模型在所有指标上均达到 100%。详细结果如表 8-1 所示。

**表 8-1：V3B 模型评估结果**

| 任务类型 | Coverage | Format | Refusal | 样本数 | 目标阈值 | 达标状态 |
|:---|---:|---:|---:|---:|:---|:---|
| Style | 1.00 | 1.00 | 1.00 | 11 | >0.90, >0.95 | ✅ 超标 |
| Writing (multitask) | 1.00 | 1.00 | 1.00 | 6 | >0.85, >0.90 | ✅ 超标 |
| All | 1.00 | 1.00 | 1.00 | 17 | >0.88, >0.92 | ✅ 超标 |

**分任务类型详细分析**：

**Style 任务** (11 个样本)：
- 所有样本均正确生成 `### 结论`、`### 推导`、`### 检查` 三段式结构
- 关键知识点（物理概念、公式推导、单位检查）覆盖率 100%
- 无误拒答或误回答情况

**Writing 任务** (6 个样本)：
- 所有样本均正确生成 `### 问题诊断`、`### 改进建议`、`### 规范说明` 三段式结构
- 写作问题识别准确，改进建议具体可操作
- 规范说明引用准确，无幻觉现象

**All 联合评估** (17 个样本)：
- 多任务模型在两类任务上均保持一致的高质量输出
- 无任务间干扰或性能退化现象
- 证明多任务学习的有效性

### 8.5.3 消融实验：单任务 vs 多任务

为验证多任务学习的有效性，本文对比了单任务训练和多任务训练的效果。

**表 8-2：单任务 vs 多任务对比**

| 模型 | 训练方式 | Style Coverage | Writing Coverage | 说明 |
|:---|:---|---:|---:|:---|
| adapter_style | 单任务 | 1.00 | - | 仅在 Style 数据上训练 |
| adapter_writing | 单任务 | - | 0.00 | 仅在 Writing 数据上训练，**失败** |
| adapter_multitask | 多任务 | 1.00 | 1.00 | 在 Style + Writing 数据上联合训练 |

**关键发现**：

1. **单任务 Writing 失败**：adapter_writing 在单独训练时产生空响应，Coverage 和 Format 均为 0.00。可能原因：
   - Writing 任务数据量较小（24 个训练样本）
   - Writing 任务的模板结构较复杂
   - 缺少其他任务的辅助信号

2. **多任务学习优势**：adapter_multitask 在两类任务上均表现完美，证明：
   - 多任务学习可以缓解小样本场景下的训练不稳定问题
   - 不同任务之间存在正向迁移效应
   - 联合训练可以提高模型的泛化能力

3. **实践建议**：在小样本教学场景中，推荐使用多任务学习策略，而非为每个任务单独训练模型。

### 8.5.4 训练效率分析

**表 8-3：V3 训练实验效率对比**

| 实验 | Epochs | 训练时长 | 可训练参数 | 显存占用 | 综合评分 |
|:---|---:|---:|---:|---:|---:|
| V3A | 3 | 35 min | 13M | ~5GB | 0.71 |
| V3B | 4 | 45 min | 13M | ~5GB | 1.00 |
| V3C | 5 | 55 min | 13M | ~5GB | 1.00 |

**效率分析**：

1. **参数效率**：LoRA 方法仅训练 13M 参数（占基座模型的 0.16%），大幅降低了训练成本。

2. **时间效率**：在 A100 GPU 上，完整的四阶段训练（sample + style + writing + all）仅需 45 分钟，适合快速迭代。

3. **显存效率**：4-bit 量化使训练显存占用控制在 5GB 以内，单张消费级 GPU 即可完成训练。

4. **成本效益**：V3B 相比 V3C 训练时间减少 18%，但性能相同，体现了良好的成本效益比。

### 8.5.5 与基线模型对比

**表 8-4：V3B vs 基线模型对比**

| 模型 | Coverage | Format | Refusal | 说明 |
|:---|---:|---:|---:|:---|
| 基座模型 (Qwen3-8B) | 0.65 | 0.35 | 0.70 | 未经过领域适配 |
| V2.2 (阶段性验证) | 0.73 | 0.83 | 0.78 | 小样本验证 |
| V3B (正式训练) | **1.00** | **1.00** | **1.00** | 数据增强 + 多任务学习 |

**改进幅度**：
- Coverage: 0.65 → 1.00 (+54%)
- Format: 0.35 → 1.00 (+186%)
- Refusal: 0.70 → 1.00 (+43%)

**关键改进因素**：
1. 数据增强：V3 新增 42 条高质量样本，覆盖更多场景
2. 模板强制：所有样本强制使用结构化模板
3. 多任务学习：联合训练提高泛化能力
4. 超参数优化：V3B 的 epochs=4, lr=1e-4 配置最优

### 8.5.6 错误案例分析

虽然 V3B 在评估集上达到 100% 指标，但在实际应用中仍可能遇到以下边界情况：

**1. 超出训练分布的问题**
- 现象：当问题涉及训练数据未覆盖的知识点时，模型可能产生不准确的回答
- 缓解措施：通过 GraphRAG 检索增强，引入外部知识库

**2. 模板过度依赖**
- 现象：模型可能过度依赖固定模板，缺乏灵活性
- 缓解措施：在训练数据中增加模板变体，提高多样性

**3. 长文本处理**
- 现象：对于超长问题（>2048 tokens），模型可能截断或遗漏信息
- 缓解措施：实现滑动窗口或分段处理机制

### 8.5.7 评估结论

V3B 后训练模型在所有评估指标上均达到 100%，显著超过预设目标阈值。主要成果包括：

1. **高质量输出**：所有样本均符合教学模板要求，关键点覆盖完整
2. **多任务能力**：单一模型可同时处理 Style 和 Writing 两类任务
3. **训练效率**：45 分钟即可完成完整训练，适合快速迭代
4. **部署友好**：4-bit 量化后显存占用仅 5GB，可在消费级 GPU 上部署

这些结果证明了本文提出的"数据增强 + 多任务学习 + LoRA 微调"方案在教学场景中的有效性，为后续的规模化应用奠定了基础。

---

**本章小结**：通过系统的评估实验，本文验证了 V3B 后训练模型在教学场景中的优异表现。消融实验证明了多任务学习的必要性，效率分析展示了 LoRA 方法的实用价值。这些结果为智能教学平台的实际部署提供了可靠的技术支撑。
