\chapter{总结与展望}
本文围绕研究生专业英文写作教学中“反馈成本高、个体差异大、建议难追溯”等问题，提出并实现了一套以学生为中心的智能教学平台。平台以写作任务为主线，贯通写作提交、智能分析、个性化反馈与教师复核，并将过程性数据沉淀为学习事件与学生画像，从而支持纵向追踪与持续改进。系统在工程上采用分层与服务化设计：后端负责业务与权限治理，AI 服务负责编排对话辅导、引导式学习、写作分析、工具调用与 GraphRAG 检索增强，并通过 OpenAI-compatible 接口对接上游推理服务。为降低幻觉并提升可追溯性，平台将课程规范与范文片段构建为知识库索引，在生成反馈时注入证据片段并要求引用编号。为支撑后续模型定制，本文实现了数据规范、LoRA/QLoRA 训练脚本与评测脚本，并在样例数据上完成端到端验证。此外，客户端侧通过共享 types 与统一 SDK 保证 Web/Mobile 的调用契约一致，为跨端交付与扩展提供基础。

后续工作可从以下方面继续推进：一是完善知识抽取与融合策略，引入实体关系抽取与图数据库，提高知识图谱的细粒度与可维护性；二是构建更系统的课程问答评测集，量化准确率、引用一致性与教学效果；三是优化检索与上下文压缩策略，降低响应时延；四是完善企业微信 OAuth 与消息推送能力，提升真实教学场景下的使用体验。

结合写作课程的试点需求，本文进一步的工作重点包括：\textbf{(1) 数据层面}持续收集真实写作样本与教师反馈，并引入教师模型生成与筛选的数据蒸馏策略，建立 100k 规模训练集与固定回归集；\textbf{(2) 模型层面}在 Qwen3 8B 上开展分阶段 LoRA/QLoRA 微调（tool/rag/style）并进行多任务合并训练；\textbf{(3) 评价层面}完善 rubric 一致性、引用可追溯性与可采纳性等指标，形成更贴近教学目标的评估体系；\textbf{(4) 工程层面}扩展写作场景的可验证工具（如引用格式与结构要素检查），并通过课堂试用与教师复核闭环持续改进系统质量。
