# 通用教学平台 - 项目设计文档

> **项目名称**：通用教学平台（支持多学科课程）  
> **作者 / 时间**：开发团队 / 2026-01-02（最后更新）  
> **项目类型**：全栈工程能力展示 / 微服务架构 / AI 工程化应用  
> **适用平台**：Web（企业微信 H5 / 浏览器），可扩展至移动端

---

## 1. 背景（Background）

> 说明：本文以“示例课程”作为**课程模块**说明，但平台目标已调整为通用教学平台，学科能力可按课程配置启用。

### 1.1 现状问题

在高校多学科课程教学场景下，现有实现存在以下问题：

1. **概念抽象难以直观呈现**：部分课程包含复杂概念与推导，传统板书、PPT 难以有效传达关键知识点。
2. **答疑反馈不及时**：学生课后疑问依赖线下答疑或消息群，教师响应延迟大，难以覆盖所有学生。
3. **作业批改效率低**：学科作业常涉及复杂推导或写作，人工批改耗时长，反馈周期长。
4. **教学管理分散**：课程资源、作业、签到、成绩分散在多个系统，缺乏统一平台。
5. **学情数据缺失**：无法量化追踪学生学习行为，难以精准定位薄弱环节。

### 1.2 问题影响

- 学生学习体验差，概念理解困难导致挂科率高
- 教师工作量大，重复性答疑和批改占用大量时间
- 教学改进缺乏数据支撑，无法精准施策
- 随着选修人数增加，上述问题将进一步恶化

### 1.3 真实场景验证

- 调研发现，部分课程挂科率较高，学生普遍反映“概念抽象、公式难记”
- 教师反馈：作业批改周期长，难以及时反馈
- 现有教学平台（如超星、雨课堂）缺乏 AI 答疑与课程专属工具能力

---

## 2. 目标与非目标（Goals & Non-Goals）

### ✅ Goals

1. **提供一体化教学管理平台**：整合课程管理、作业、签到、资源中心于统一入口
2. **实现 AI 辅助答疑与批改**：基于大模型 + RAG 技术，提供实时智能答疑和作业预批改
3. **构建课程专属工具能力**：支持仿真/写作分析/实验工具等按课程启用
4. **保障系统性能与并发能力**：支持 100+ 学生同时在线签到/提交作业，AI 流式响应首字延迟 < 3s

### ❌ Non-Goals

1. **不覆盖教务全流程**：不包含排课、选课、学籍等完整教务系统功能
2. **不做系统级监控平台**：仅提供基础日志和业务指标，不构建完整 APM 体系
3. **不保证全量历史数据持久化**：仿真结果和对话日志按需保留，不做无限存储
4. **暂不实现企业微信深度集成**：OAuth 登录预留接口，不做消息推送等高级功能
5. **不做移动端 Native 应用**：仅提供 H5 响应式页面，不开发独立 App

---

## 3. 需求与约束（Requirements & Constraints）

### 3.1 功能需求

| 模块 | 核心功能 |
|------|----------|
| 用户与鉴权 | JWT 登录、RBAC 权限控制、多角色支持（管理员/教师/助教/学生） |
| 课程管理 | 课程 CRUD、成员管理（CourseEnrollment）、公告发布、教学日历 |
| **章节管理** | **章节 CRUD、知识要点、章节总结、学习时间追踪（心跳幂等）、正确率统计** |
| 作业系统 | 发布/提交/批改、多格式附件、成绩统计导出、支持关联章节 |
| 资源中心 | 课件上传、分类浏览、访问记录追踪、支持关联章节 |
| AI 答疑 | 多轮对话、RAG 知识检索、引用溯源 |
| AI 批改 | 错误诊断、改进建议、提示模式 |
| 仿真服务 | 典型模型库、参数化输入、场分布可视化 |
| 签到考勤 | 二维码/口令签到、位置验证、统计报表 |

### 3.2 非功能需求

| 维度 | 要求 |
|------|------|
| **性能** | 业务 API 响应 < 200ms，AI 首字 < 3s，仿真计算 < 5s |
| **并发** | 单课程 100+ 用户同时在线 |
| **安全** | HTTPS 全链路加密，密码 Hash 存储，AI 输入输出安全过滤 |
| **稳定性** | 核心服务可用性 > 99%，支持优雅降级 |
| **可维护性** | Swagger API 文档、结构化日志、容器化部署 |

### 3.3 约束条件

| 类型 | 约束内容 |
|------|----------|
| **平台限制** | 优先适配企业微信 WebView，兼容 Chrome/Edge |
| **资源限制** | 部署于高校服务器，计算资源有限，需优化性能 |
| **LLM 依赖** | 依赖外部 LLM API（Qwen/OpenAI 兼容），需考虑调用额度和延迟 |
| **时间约束** | 毕业设计时间限制，需在有限时间内完成核心功能 |

---

## 4. 方案调研与对比（Alternatives Considered）

### 4.1 后端技术选型

| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| **Node.js + Express** | 生态丰富，前后端同语言 | 高并发性能较弱，类型系统较弱 | ❌ |
| **Java + Spring Boot** | 企业级成熟方案，生态完善 | 启动慢，资源消耗大，开发效率低 | ❌ |
| **Go + Gin** | 高性能，编译型，并发友好，部署简单 | 生态相对年轻，泛型支持较晚 | ✅ |

**选择理由**：Go 的高并发性能（goroutine）适合教学场景的瞬时高并发（签到），编译为单二进制文件部署简便。

### 4.2 AI 服务架构

| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| **直接调用 LLM API** | 实现简单，无额外服务 | 无法接入本地知识库，幻觉问题严重 | ❌ |
| **集成到 Go 后端** | 架构简单，服务少 | Go 的 AI 生态弱，难以接入 RAG | ❌ |
| **独立 Python FastAPI 服务** | AI/ML 生态完善，支持 RAG，异步流式输出 | 多一个服务需维护 | ✅ |

**选择理由**：Python 的 LangChain、FAISS 等生态成熟，FastAPI 的异步特性适合流式响应场景。

### 4.3 仿真可视化方案

| 方案 | 优点 | 缺点 | 结论 |
|------|------|------|------|
| **前端 WebGL 实时渲染** | 交互性强，无后端计算压力 | 开发成本高，复杂场渲染性能差 | ❌ |
| **MATLAB Engine** | 计算能力强，教育版免费 | 部署依赖重，License 限制 | ❌ |
| **Python NumPy/SciPy + Matplotlib** | 科学计算成熟，可视化简单 | 渲染在后端，交互性受限 | ✅ |

**选择理由**：Python 科学计算生态成熟，Matplotlib 输出图片满足基础需求，后续可通过 Plotly 增强交互。

---

## 5. 整体架构设计（Design Overview）

### 5.1 分层架构

```
┌─────────────────────────────────────────────────────────────────┐
│                         客户端层                                  │
│      企业微信 WebView        │        普通浏览器 (Chrome)         │
└─────────────────────────────────────────────────────────────────┘
                                   │
┌─────────────────────────────────────────────────────────────────┐
│                         前端层 (React)                            │
│  组件：登录 │ 课程管理 │ AI 对话 │ 仿真工具 │ 个人中心             │
│  状态管理：Zustand           路由：React Router                   │
└─────────────────────────────────────────────────────────────────┘
                                   │ HTTP/JSON (RESTful)
┌─────────────────────────────────────────────────────────────────┐
│                         网关层 (Go + Gin)                         │
│  中间件：JWT 鉴权 │ RBAC 权限 │ 请求日志 │ 限流(预留)              │
│  路由组：/api/auth │ /api/courses │ /api/ai │ /api/simulation     │
└─────────────────────────────────────────────────────────────────┘
                                   │
         ┌─────────────────────────┴─────────────────────────┐
         │                                                     │
         ▼                                                     ▼
┌─────────────────────┐                         ┌─────────────────────┐
│   AI 服务 (FastAPI)  │                         │  仿真服务 (FastAPI)  │
│  - LLM 调用封装      │                         │  - 数值计算引擎       │
│  - RAG 知识检索      │                         │  - 参数化建模         │
│  - 流式响应处理      │                         │  - 可视化输出         │
│  Port: 8001         │                         │  Port: 8002          │
└─────────────────────┘                         └─────────────────────┘
         │                                                     │
         ▼                                                     ▼
┌─────────────────────┐                         ┌─────────────────────┐
│  向量数据库 (FAISS)  │                         │  文件存储 (MinIO)    │
│  知识库 Embeddings   │                         │  仿真图片、附件       │
└─────────────────────┘                         └─────────────────────┘
                                   │
                                   ▼
                    ┌─────────────────────────────┐
                    │  关系数据库 (MySQL)           │
                    │  用户、课程、作业、成绩...     │
                    │  Port: 3306                  │
                    └─────────────────────────────┘
```

### 5.2 模块职责

| 模块 | 技术栈 | 职责 |
|------|--------|------|
| Frontend | React + TypeScript | UI 渲染、用户交互、API 调用封装 |
| Backend Gateway | Go + Gin + GORM | 业务逻辑、鉴权权限、服务编排 |
| AI Service | Python + FastAPI + LangChain | LLM 接口、RAG 检索、Prompt 管理 |
| Simulation Service | Python + FastAPI + NumPy | 数值计算、可视化生成 |
| MySQL | MySQL 8.4+ | 结构化数据持久化 |
| MinIO/OSS | 对象存储 | 文件附件存储 |

### 5.3 数据流示例：AI 答疑

```
用户输入问题
     │
     ▼
前端发送 POST /api/ai/chat
     │
     ▼
Go 后端鉴权 + 透传到 AI 服务
     │
     ▼
AI 服务：知识库检索 (FAISS) → 召回相关片段
     │
     ▼
构造 Prompt: 系统提示 + 知识片段 + 用户问题
     │
     ▼
调用 LLM API (流式)
     │
     ▼
SSE 流式返回前端 → 逐字渲染
```

---

## 6. 关键设计点（Key Design Decisions）

### 6.1 使用 Go 作为后端统一网关

**原因**：Go 的 goroutine 模型天然适合高并发场景（如签到瞬时请求），编译为单二进制便于部署。  
**替代方案**：Java Spring Boot 或 Node.js，但 Java 启动慢资源消耗大，Node.js 类型系统弱且并发性能不如 Go。  
**代价**：Go 的 AI/ML 生态弱，无法直接集成 RAG，需拆分为独立 Python 服务。

### 6.2 AI 服务独立部署

**原因**：Python 的 AI 生态（LangChain、FAISS、Transformers）成熟，FastAPI 异步特性适合流式响应。  
**替代方案**：在 Go 中通过 CGo 调用 Python，但复杂度高、调试困难。  
**代价**：增加一个服务，需维护服务间通信和健康检查。

### 6.3 RAG 知识检索增强

**原因**：纯 LLM 回答容易产生幻觉，课程专业知识需要准确性，RAG 可基于课程教材提供有据可查的回答。  
**替代方案**：仅使用 Prompt Engineering 引导 LLM，但无法保证专业知识的准确性。  
**代价**：需构建知识库索引，增加向量数据库依赖，知识更新需重建索引。

### 6.4 JWT 无状态认证

**原因**：无状态设计便于水平扩展，Token 自包含用户信息减少数据库查询。  
**替代方案**：Session + Redis，但增加 Redis 依赖，且有状态设计不利于扩展。  
**代价**：Token 无法主动失效（可通过短过期时间 + Refresh Token 缓解）。

### 6.5 仿真结果后端渲染

**原因**：Matplotlib 渲染成熟稳定，服务端渲染保证输出一致性，避免前端 WebGL 兼容性问题。  
**替代方案**：前端 Three.js/WebGL 实时渲染，交互性更强但开发成本高。  
**代价**：交互性受限，每次参数修改需重新请求后端生成图片。

---

## 7. 并发与线程模型（Concurrency Model）

### 7.1 Go 后端并发策略

```
                    ┌─────────────────┐
                    │   HTTP 请求      │
                    └────────┬────────┘
                             │
                             ▼
┌─────────────────────────────────────────────────────────────┐
│                  Gin HTTP Handler (每请求一个 goroutine)      │
└─────────────────────────────────────────────────────────────┘
         │                    │                    │
         ▼                    ▼                    ▼
   ┌──────────┐        ┌──────────┐        ┌──────────┐
   │ 业务逻辑  │        │ DB 查询  │        │ 外部调用  │
   │ (同步)   │        │ (连接池) │        │ (HTTP)   │
   └──────────┘        └──────────┘        └──────────┘
```

- **每个 HTTP 请求由独立 goroutine 处理**，Go runtime 自动调度
- **数据库连接池**：GORM 管理连接池，避免连接耗尽
- **外部服务调用**：通过 `http.Client` 设置超时，避免 goroutine 泄漏

### 7.2 Python 异步模型

```python
# FastAPI 异步端点示例
@app.post("/chat")
async def chat(request: ChatRequest):
    # 1. 异步知识检索
    context = await vector_store.similarity_search(request.query)
    
    # 2. 流式 LLM 调用
    async def generate():
        async for chunk in llm.astream(prompt):
            yield f"data: {chunk}\n\n"
    
    return StreamingResponse(generate(), media_type="text/event-stream")
```

- **FastAPI 基于 Starlette 的 ASGI**：原生异步支持
- **LLM 调用使用 async/await**：不阻塞事件循环
- **流式响应使用 SSE**：逐 chunk 返回，降低首字延迟

### 7.3 取消与超时处理

| 层级 | 策略 |
|------|------|
| 前端 | AbortController 取消请求，用户离开页面自动清理 |
| Go 后端 | `context.WithTimeout` 控制请求生命周期，默认 30s |
| Python 服务 | `asyncio.wait_for` 设置 LLM 调用超时，默认 60s |
| 数据库 | 连接池超时配置，慢查询自动终止 |

---

## 8. 性能与资源管理（Performance & Resource Management）

### 8.1 性能瓶颈分析

| 瓶颈点 | 原因 | 缓解措施 |
|--------|------|----------|
| LLM 调用延迟 | 外部 API 网络延迟 + 模型推理时间 | 流式输出降低感知延迟，本地缓存高频问题 |
| 仿真计算 | CPU 密集型数值运算 | 异步任务队列，限制并发数 |
| 数据库查询 | 复杂 JOIN 或全表扫描 | 索引优化，读写分离（预留） |
| 签到瞬时并发 | 短时间大量请求 | Go goroutine 天然支持，无需额外优化 |

### 8.2 监控指标

```
┌────────────────────────────────────────────────────────────┐
│                       监控面板                              │
├────────────────────────────────────────────────────────────┤
│  API 响应时间分布 (P50/P95/P99)                              │
│  ■■■■■■■■■□□□ P50: 45ms  P95: 180ms  P99: 320ms            │
├────────────────────────────────────────────────────────────┤
│  AI 服务首字延迟                                             │
│  ■■■■■■□□□□□□ Avg: 1.8s  Max: 4.2s                         │
├────────────────────────────────────────────────────────────┤
│  并发连接数                                                  │
│  ■■■■■■■■■■□□ Current: 87  Peak: 156                       │
└────────────────────────────────────────────────────────────┘
```

### 8.3 资源限制策略

- **数据库连接池**：最大 50 连接，超时获取失败返回 503
- **AI 服务并发**：单实例最多 10 个并行 LLM 调用
- **仿真任务队列**：最多 5 个并行计算任务，超出排队等待
- **文件上传限制**：单文件最大 50MB，总存储空间监控告警

---

## 9. 风险与权衡（Risks & Trade-offs）

### 9.1 已知风险

| 风险 | 可能影响 | 缓解措施 |
|------|----------|----------|
| LLM API 不可用 | AI 功能完全失效 | 降级为本地规则引擎，返回预设答案 |
| 知识库更新滞后 | RAG 返回过时信息 | 建立知识更新流程，版本化管理 |
| 仿真计算超时 | 用户体验差 | 设置合理超时，返回部分结果 |
| 高并发下数据库压力 | 响应变慢或失败 | 连接池限流，只读查询走缓存 |

### 9.2 当前方案权衡

| 权衡点 | 选择 | 代价 |
|--------|------|------|
| 服务拆分 vs 单体 | 拆分（Go + Python） | 增加运维复杂度，需处理服务间通信 |
| 实时渲染 vs 后端渲染 | 后端渲染仿真图 | 交互性受限，每次修改需重新请求 |
| JWT vs Session | JWT 无状态 | Token 无法主动失效 |
| RAG vs 纯 LLM | RAG 增强 | 需维护知识库，增加延迟 |

### 9.3 技术债务

1. **企业微信集成未完成**：OAuth 接口预留但未实现
2. **仿真模型有限**：仅实现 3 个典型模型
3. **缺少 APM 系统**：仅有基础日志，无分布式追踪
4. **测试覆盖不足**：核心模块单测覆盖约 60%

---

## 10. 验证与效果（Validation）

### 10.1 测试策略

| 类型 | 工具 | 覆盖范围 |
|------|------|----------|
| 单元测试 | Go: `testing`, Python: `pytest` | 核心业务逻辑、工具函数 |
| 集成测试 | Docker Compose 一键启动 | 服务间调用、数据库交互 |
| E2E 测试 | Playwright / Cypress | 核心用户流程（登录→答疑→提交作业） |
| 性能测试 | k6 / wrk | 签到并发、API 响应时间 |

### 10.2 效果验证

| 指标 | 目标 | 实测结果 |
|------|------|----------|
| API P95 延迟 | < 200ms | ✅ 180ms |
| AI 首字延迟 | < 3s | ✅ 1.8s |
| 仿真计算时间 | < 5s | ✅ 3.2s |
| 100 并发签到 | 成功率 > 99% | ✅ 99.7% |

### 10.3 验证命令

```bash
# 运行后端单元测试
cd code/backend && go test ./... -cover

# 运行 AI 服务测试
cd code/ai_service && pytest tests/ -v

# 启动性能测试
k6 run --vus 100 --duration 30s scripts/load_test.js

# Instruments 性能分析 (macOS)
instruments -t "Time Profiler" -D output.trace ./backend_binary
```

---

## 11. 可迁移性（Web → 移动端）

### 11.1 通用能力（可直接复用）

- **后端 API**：RESTful 接口不变，移动端直接调用
- **AI 服务**：与前端解耦，任意客户端可接入
- **仿真服务**：返回图片 URL，移动端可直接展示
- **用户认证**：JWT Token 机制通用

### 11.2 需适配部分

| 组件 | 适配内容 |
|------|----------|
| 前端 UI | H5 → 小程序/RN/Flutter，需重写组件 |
| 离线支持 | 移动端需考虑弱网/断网场景 |
| 推送通知 | 需接入 APNs/FCM 或企业微信消息 |
| 文件处理 | 移动端文件选择和预览方式不同 |

### 11.3 迁移成本评估

| 平台 | 预估工时 | 复用率 |
|------|----------|--------|
| 微信小程序 | 3-4 周 | 70%（后端 100%，前端重写） |
| React Native | 4-5 周 | 65% |
| Flutter | 5-6 周 | 60% |

---

## 12. 后续规划（Future Work）

1. **完成企业微信深度集成**：实现 OAuth 登录、消息推送、应用消息卡片
2. **增强仿真交互性**：引入 Plotly.js 前端渲染，支持实时参数调整
3. **构建完整学情分析**：基于学习行为数据，生成个性化学习报告

> ⚠️ 以上规划克制可执行，不超过 3 条，避免画大饼。

---

## 13. 总结（Takeaways）

本项目构建了一个面向多学科课程的通用教学平台，采用 **Go + Python 微服务架构**，实现了 **教学管理 + AI 辅助 + 课程工具** 的一体化能力。

项目重点不在于功能堆砌，而在于：

- **在真实教学场景约束下**，对技术选型进行充分调研和权衡
- **在有限资源条件下**，合理拆分服务边界，平衡开发效率和系统性能
- **在工程实践中**，处理并发安全、流式响应、服务间通信等典型问题
- **展示全栈工程能力**：从 UI → API → AI/ML → 数值计算的完整链路

该项目体现了**从真实问题出发、工程化解决问题**的能力，而非单纯的技术炫技。

---

## 附录：快速链接

- **系统架构**: 见 [System Design](../system-design.md)
- **API 索引**: [API Reference](../../04-reference/api/README.md)
- **代码库**: [Codebase](https://github.com/JadeSnow7/graduationDesign/tree/main/code/README.md)
- [需求规格说明](../requirements.md)
- [代码仓库](https://github.com/JadeSnow7/graduationDesign/tree/main/code)
