\chapter{系统关键模块设计与实现}

\section{技能系统与对话编排}
平台将"提示模板、上下文注入、输出约束、安全规则"封装为可复用的技能单元，并通过注册表集中管理。运行时以 \texttt{mode} 参数选择技能，解决了"提示词散落、行为不可控"的工程问题，使系统具备可维护的提示治理能力。

\subsection{技能注册与路由}
AI 服务层将技能定义为一组可调用的能力模块，并为历史模式名提供别名映射以保持接口兼容。平台同时支持 \texttt{\_rag} 后缀约定：当 \texttt{mode} 以 \texttt{\_rag} 结尾时，在保持技能教学风格不变的前提下启用 GraphRAG 检索增强，实现"技能（风格）—检索（证据）"的解耦组合。

\subsection{上下文注入与输出治理}
为使回答贴合课程语境且便于前端结构化展示，技能系统在系统提示中约定输出组织方式（例如先给出结论或评价，再展开解释与建议），并在不干扰用户对话的前提下注入必要上下文：课程信息、作业要求、学生档案与检索证据等。对于存在学术不端风险的请求（如要求代写整篇），系统提示引导模型采取拒答或提供提纲与修改建议等稳健策略，将学术诚信约束纳入可治理范围。

\subsection{已实现技能与能力边界}
从工程落地角度，平台将技能分为"通用能力"与"课程专属能力"两类：
\begin{enumerate}[label=(\arabic*)]
  \item \textbf{通用能力}：概念讲解、作业反馈、引导式学习与个性化辅导策略等，强调结构化输出与过程性引导，可迁移到不同课程。
  \item \textbf{课程专属能力}：以电磁场为例的公式推导与仿真解读；以写作为例的写作类型感知评估与学术规范反馈。课程专属能力通过权限与开关边界控制，避免跨课程误用。
\end{enumerate}
该划分使平台在扩展课程时优先复用通用能力，仅在必要处以课程模块补齐差异化需求。

\section{GraphRAG 检索增强实现}
平台在 AI 服务层实现轻量化 GraphRAG：离线阶段将课程材料切片并构建图结构索引；在线阶段通过混合检索与图扩展获取相关证据片段，并将其注入系统消息，要求回答按引用编号输出。相较传统 RAG，该方案在概念依赖关系较强的任务中更容易覆盖前置概念与相关规范；同时，引用编号为教师复核与错误定位提供了直接抓手。检索阶段支持按课程维度的访问控制，保证不同课程材料隔离。

\section{工具调用执行器与安全治理}

\subsection{调用流程与消息组织}
平台在对话接口中提供工具调用能力：当模型判断需要可验证结果时，生成结构化 \texttt{tool\_calls}；系统解析后执行工具，并以 \texttt{tool} 消息将执行结果回注到对话上下文；随后模型基于工具结果生成最终解释与建议。该"调用—执行—回注—解释"链路使关键数值可复现、可审计。

\subsection{安全约束与可控性}
为避免模型进入无限调用或越权调用状态，平台在工程上引入以下约束：
\begin{enumerate}[label=(\arabic*)]
  \item \textbf{工具白名单}：仅允许调用预先注册的工具，未注册名称直接拒绝执行。
  \item \textbf{最大调用次数}：每次对话限制最大工具调用轮数。
  \item \textbf{超时与降级}：工具执行设置超时；不可用时返回失败信息并引导模型给出替代方案。
  \item \textbf{结果回注}：工具输出以结构化文本或 JSON 形式回注，保证后续回答引用的是可复现的外部结果。
\end{enumerate}

\section{引导式学习与学习状态追踪}
平台将引导式学习作为"学生中心"的核心交互方式：系统围绕学习主题生成学习路径，并在多轮对话中维护进度、薄弱点与阶段性目标，实现"诊断—引导—巩固"的过程性辅导。

\subsection{学习路径生成与会话管理}
引导式学习首先生成结构化学习路径（3--6 步），并为每一步附带目标描述、前置概念与是否需要工具验证等标记。系统以 \texttt{session\_id} 绑定会话与用户身份，并引入有效期与会话数量上限，避免无界增长与越权访问。会话推进过程中，系统维护学习目标、当前步骤、历史对话与步骤完成状态。

\subsection{薄弱点检测与学习画像}
平台对辅导过程中的"纠错/提示"语句进行轻量解析，在负面信号上下文中提取概念薄弱点（如写作中的"逻辑连接"或理工科中的"边界条件"），并在会话内累积统计。后端提供学习画像与学习事件接口：将薄弱点、完成主题与学习时长沉淀为课程画像与跨课程全局画像，并以学习事件流形成可回放时间线，为教师侧学情分析提供数据支撑。

\subsection{个性化辅导策略生成}
在具备学习档案后，系统可基于历史薄弱点与学习进度生成结构化辅导策略，例如 1--2 周学习计划、针对薄弱点的专项练习与推荐主题。该能力同样通过技能系统实现，输出结构化数据便于前端展示与教师复核。

\section{异构加速服务部署}
AI 服务通过 OpenAI-compatible 接口与上游推理服务对接，部署侧支持 GPU、NPU 与 FPGA 三种异构加速后端，分别针对大模型推理与向量检索进行优化。

\subsection{GPU 推理部署}
GPU 方案采用 vLLM 作为推理引擎，加载 Hugging Face 格式模型，支持连续批处理与 PagedAttention 以提升吞吐。部署时通过 Docker 容器化，配置 CUDA 驱动与显存限制即可启动。该方案在 NVIDIA RTX 4090 上可获得较低延迟与较高吞吐。

\subsection{Ascend NPU 推理部署}
为满足国产化与节能需求，平台同时支持华为 Ascend NPU 后端。部署流程如下：
\begin{enumerate}[label=(\arabic*)]
  \item \textbf{模型转换}：使用 ATC 将 Hugging Face 模型转换为 Ascend 可执行格式（OM 模型），或使用 MindIE 直接加载权重。
  \item \textbf{推理引擎}：采用 MindIE 提供 Python/C++ 推理接口，或通过 vLLM 的 Ascend 后端实现兼容。
  \item \textbf{服务封装}：推理服务对外暴露 OpenAI-compatible 接口，AI 服务层无需区分上游是 GPU 还是 NPU 后端。
\end{enumerate}
实测表明，Ascend 910B 在首 token 延迟上与 RTX 4090 处于同一数量级，后续 token 吞吐略低约 15\%，但满载功耗降低约 20\%。

\subsection{FPGA 加速 Embedding 服务}
在检索增强链路中，Embedding 计算是主要延迟来源之一。当 GPU 被大模型推理占用时，Embedding 若共享 GPU 会产生资源竞争。平台引入 FPGA 加速方案，将 Embedding 计算迁移至 Xilinx Alveo 加速卡，实现资源解耦与延迟优化。

\textbf{实现流程}：
\begin{enumerate}[label=(\arabic*)]
  \item \textbf{模型量化}：将 Embedding 模型（如 bge-base-zh、sentence-transformers）通过 Vitis AI 量化工具转换为 INT8 精度。量化过程使用课程语料库的代表性样本进行校准，保证量化后的向量表示与 FP32 版本保持较高余弦相似度（$>0.98$）。
  \item \textbf{模型编译}：使用 Vitis AI Compiler 将量化模型编译为 FPGA 可执行指令（xmodel），指定目标设备（如 U50、U250）的 DPU 配置。
  \item \textbf{硬件部署}：在 Xilinx Alveo 加速卡上部署 xmodel，通过 DPU（Deep Learning Processing Unit）IP 核执行推理。FPGA 通过 PCIE 与主机通信，使用 VART（Vitis AI Runtime）API 进行调用。
  \item \textbf{服务封装}：将 FPGA Embedding 推理封装为 FastAPI 微服务，对外提供与 CPU/GPU Embedding 服务相同的 REST 接口（\texttt{/v1/embeddings}），便于 AI 服务层无感切换。
\end{enumerate}

\textbf{接口设计}：
\begin{verbatim}
POST /v1/embeddings
{
  "model": "bge-base-zh-fpga",
  "input": ["query text 1", "query text 2"]
}
Response:
{
  "data": [
    {"embedding": [0.1, 0.2, ...], "index": 0},
    {"embedding": [0.3, 0.4, ...], "index": 1}
  ]
}
\end{verbatim}

\textbf{配置切换}：AI 服务通过环境变量 \texttt{EMBEDDING\_BACKEND} 选择后端（\texttt{cpu}、\texttt{gpu}、\texttt{fpga}），无需修改业务代码即可切换。

\section{训练、蒸馏与评测管线}
为提升模型在教学风格、引用规范、工具调用与引导式学习等能力上的稳定性，平台提供可复现的训练与评测工具链。

\subsection{数据规范与样本类型}
训练数据采用 chat-style JSONL 表示：每条样本包含 \texttt{mode} 与多轮 \texttt{messages}，与运行时接口保持一致。数据按任务属性分桶组织，典型包括：
\begin{enumerate}[label=(\arabic*)]
  \item \textbf{教学风格与结构化输出}：约束"先结论—再解释—再建议"的组织方式，保证格式可解析。
  \item \textbf{RAG 引用约束}：注入证据片段并要求仅基于片段作答，强制标注引用编号，证据不足时追问或拒答。
  \item \textbf{工具调用样本}：包含工具调用请求与结果回注，使模型学会在需要可验证结果时触发工具并正确解释。
  \item \textbf{拒答与追问}：对缺参、超范围或学术不端请求给出稳健行为。
\end{enumerate}
数据规范化的直接收益是训练与上线协议对齐，减少格式漂移导致的线上不稳定。

\subsection{LoRA/QLoRA 微调与产物管理}
平台采用 LoRA/QLoRA\cite{hu2021lora,dettmers2023qlora} 对基座模型进行参数高效微调，并将产物以 adapter 形式输出。训练侧同时输出 adapter 权重、训练配置与日志；支持训练完成后自动生成预测与评测报告，形成可对比的版本迭代依据。

\subsection{数据蒸馏与质量门禁}
在启动微调前，平台引入"蒸馏 + smoke"作为前置门禁：将 chat-style 数据蒸馏为易于审阅的格式并统计去重率；随后以分钟级轻量指标验证数据链路可用，用于发现空样本、重复激增或字段缺失等问题。smoke 指标仅用于链路检查，不用于宣称最终效果。

\section{课程示例模块}

\subsection{电磁场：数值仿真与推导验证}
对电磁场类推导与计算任务，平台可扩展数值仿真与可视化能力，并通过工具调用将关键计算交由可执行组件完成。例如，采用有限差分法求解二维静电场（Laplace/Poisson 方程）或同轴线电容场分布，输出字段数据与可视化图像，再由模型结合引用证据与仿真结果进行解释与引导，形成"计算—解释—理解"的教学闭环。

\subsection{研究生专业英文写作：结构化评价与规范反馈}
对写作类课程，系统以结构化评价维度（rubrics）组织反馈，强调问题定位、修改顺序与可执行建议；对引用规范、段落结构与格式等硬约束项，可交由工具进行规则化检查，减少凭空建议的风险。技能提示中显式加入学术诚信约束，默认不代写整篇内容，而以示范片段、段落框架与改写建议辅助学生完成迭代。

\section{本章小结}
本章围绕平台工程落地给出关键模块的设计与实现：以技能系统进行能力编排与治理；以 GraphRAG 提供可追溯证据链；以工具调用提供可验证执行链；以引导式学习与学习画像实现过程性辅导与长期追踪；异构加速层支持 GPU、NPU 与 FPGA 三种后端——GPU/NPU 用于大模型推理，FPGA 用于 Embedding 服务的低延迟加速与资源解耦；训练、蒸馏与评测管线支撑能力迭代。下一章将从测试与实验评估角度验证系统方案与实现效果。
